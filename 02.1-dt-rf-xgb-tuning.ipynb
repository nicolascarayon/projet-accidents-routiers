{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_libs import lib_tools as pt\n",
    "\n",
    "run_gridSearchCV = True  # True to run hyperparameters optimization with GridSearchCV()\n",
    "run_optuna = True        # True to run hyperparameters optimization with Optuna\n",
    "\n",
    "# run_type = 'very-light'\n",
    "run_type = 'light'\n",
    "# run_type = 'full'\n",
    "\n",
    "if run_type == 'very-light': filename_train, filename_test = 'df-very-light-train.pkl', 'df-very-light-test.pkl'\n",
    "if run_type == 'light'     : filename_train, filename_test = 'df-light-train.pkl', 'df-light-test.pkl'\n",
    "if run_type == 'full'      : filename_train, filename_test = 'df-full-train.pkl', 'df-full-test.pkl'\n",
    "\n",
    "# classifier_name = 'DecisionTreeClassifier'\n",
    "# classifier_name = 'RandomForestClassifier'\n",
    "# classifier_name = 'GradientBoostingClassifier'\n",
    "\n",
    "columns = ['catv', 'agg', 'dep', 'col', 'catr', 'catu', 'trajet', 'locp', 'circ', 'situ', 'lum', 'age_cls']\n",
    "X_train, y_train, X_test, y_test, X_test_final, y_test_final = pt.get_train_valid_test_data(filename_train, filename_test, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:122: FutureWarning: Default parameter min_samples_leaf will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter min_samples_leaf will change in version 2.6.\"\n",
      "C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\category_encoders\\target_encoder.py:127: FutureWarning: Default parameter smoothing will change in version 2.6.See https://github.com/scikit-learn-contrib/category_encoders/issues/327\n",
      "  warnings.warn(\"Default parameter smoothing will change in version 2.6.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes cardinality after resampling :\n",
      "0    48878\n",
      "1    48878\n",
      "Name: grav, dtype: int64\n",
      "X shape : (97756, 12)\n",
      "Columns target encoded : ['dep']\n",
      "Columns one hot encoded : Index(['catv', 'agg', 'col', 'catr', 'catu', 'trajet', 'locp', 'circ', 'situ',\n",
      "       'lum', 'age_cls'],\n",
      "      dtype='object')\n",
      "Features normalized\n",
      "--- Train set - features encoding performed in 281.00 seconds ---\n",
      "--- Test set - features encoding performed in 0.41 seconds ---\n",
      "--- Test set - features encoding performed in 0.48 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from my_libs.encoder_custom import EncoderCustom\n",
    "\n",
    "cols_target_encoded = ['dep']\n",
    "cols_onehot_encoded = X_train.columns.drop(cols_target_encoded)\n",
    "\n",
    "encoder = EncoderCustom(cols_target_encoded=cols_target_encoded, cols_onehot_encoded=cols_onehot_encoded)\n",
    "X_train, y_train = encoder.transform(X_train, y_train, 'Train')\n",
    "X_test, y_test = encoder.transform(X_test,  y_test,  'Test')\n",
    "X_test_final, y_test_final = encoder.transform(X_test_final, y_test_final, 'Test')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-02-19 23:23:01,249]\u001B[0m A new study created in memory with name: no-name-f9bdda33-e78f-4e45-a65e-6fa557ef449d\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:23:02,673]\u001B[0m Trial 0 finished with value: 0.7166658041195375 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 5, 'min_samples_split': 6}. Best is trial 0 with value: 0.7166658041195375.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.2s finished\n",
      "\u001B[32m[I 2023-02-19 23:23:24,024]\u001B[0m Trial 1 finished with value: 0.7835206354970028 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 42, 'criterion': 'gini'}. Best is trial 1 with value: 0.7835206354970028.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.0s finished\n",
      "\u001B[32m[I 2023-02-19 23:23:27,096]\u001B[0m Trial 2 finished with value: 0.7652026637516283 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 26, 'min_samples_split': 6}. Best is trial 1 with value: 0.7835206354970028.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.4s finished\n",
      "\u001B[32m[I 2023-02-19 23:23:50,620]\u001B[0m Trial 3 finished with value: 0.7856510911721721 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 42, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.1s finished\n",
      "\u001B[32m[I 2023-02-19 23:24:02,845]\u001B[0m Trial 4 finished with value: 0.782502181371031 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 23, 'criterion': 'gini'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.0s finished\n",
      "\u001B[32m[I 2023-02-19 23:24:04,977]\u001B[0m Trial 5 finished with value: 0.726065463105161 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 8, 'min_samples_split': 6}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.2s finished\n",
      "\u001B[32m[I 2023-02-19 23:24:31,310]\u001B[0m Trial 6 finished with value: 0.784392800328131 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 46, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.2s finished\n",
      "\u001B[32m[I 2023-02-19 23:24:39,585]\u001B[0m Trial 7 finished with value: 0.7823106081280394 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 15, 'criterion': 'gini'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "\u001B[32m[I 2023-02-19 23:24:40,364]\u001B[0m Trial 8 finished with value: 0.6368174688246739 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 3, 'min_samples_split': 3}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "\u001B[32m[I 2023-02-19 23:24:41,423]\u001B[0m Trial 9 finished with value: 0.676417837096012 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 4, 'min_samples_split': 2}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:24:46,344]\u001B[0m Trial 10 finished with value: 0.705904193405742 and parameters: {'classifier': 'GradientBoostingClassifier', 'learning_rate': 0.18303397787548367, 'n_estimators ': 7}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.4s finished\n",
      "\u001B[32m[I 2023-02-19 23:25:12,849]\u001B[0m Trial 11 finished with value: 0.7846713381969118 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 50, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.6s finished\n",
      "\u001B[32m[I 2023-02-19 23:25:38,569]\u001B[0m Trial 12 finished with value: 0.7842826899824366 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 50, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "\u001B[32m[I 2023-02-19 23:25:39,702]\u001B[0m Trial 13 finished with value: 0.6368174688246739 and parameters: {'classifier': 'GradientBoostingClassifier', 'learning_rate': 0.0011206841716947748, 'n_estimators ': 1}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:25:59,602]\u001B[0m Trial 14 finished with value: 0.7846899776725182 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 35, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:26:18,967]\u001B[0m Trial 15 finished with value: 0.784211138585169 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 34, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.2s finished\n",
      "\u001B[32m[I 2023-02-19 23:26:42,246]\u001B[0m Trial 16 finished with value: 0.7833468562246556 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 34, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.0s finished\n",
      "\u001B[32m[I 2023-02-19 23:27:03,385]\u001B[0m Trial 17 finished with value: 0.7401845689647595 and parameters: {'classifier': 'GradientBoostingClassifier', 'learning_rate': 0.869872722721052, 'n_estimators ': 30}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   24.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:27:28,265]\u001B[0m Trial 18 finished with value: 0.784745616782554 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 36, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   24.6s finished\n",
      "\u001B[32m[I 2023-02-19 23:27:52,944]\u001B[0m Trial 19 finished with value: 0.78384533131934 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 38, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "\u001B[32m[I 2023-02-19 23:27:54,043]\u001B[0m Trial 20 finished with value: 0.6368174688246739 and parameters: {'classifier': 'GradientBoostingClassifier', 'learning_rate': 0.011213909104436055, 'n_estimators ': 1}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.5s finished\n",
      "\u001B[32m[I 2023-02-19 23:28:13,695]\u001B[0m Trial 21 finished with value: 0.7844318910714568 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 29, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   24.4s finished\n",
      "\u001B[32m[I 2023-02-19 23:28:38,256]\u001B[0m Trial 22 finished with value: 0.784456357167511 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 39, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:28:57,691]\u001B[0m Trial 23 finished with value: 0.7844495775932582 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 25, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.7s finished\n",
      "\u001B[32m[I 2023-02-19 23:29:21,534]\u001B[0m Trial 24 finished with value: 0.784504984145083 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 31, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   32.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:29:54,438]\u001B[0m Trial 25 finished with value: 0.7836853365745012 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 42, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   11.4s finished\n",
      "\u001B[32m[I 2023-02-19 23:30:05,993]\u001B[0m Trial 26 finished with value: 0.7829816610767854 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 18, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.5s finished\n",
      "\u001B[32m[I 2023-02-19 23:30:27,615]\u001B[0m Trial 27 finished with value: 0.7839061630001973 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 37, 'criterion': 'gini'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.5s finished\n",
      "\u001B[32m[I 2023-02-19 23:30:54,191]\u001B[0m Trial 28 finished with value: 0.7838569242563248 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 44, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.0s finished\n",
      "\u001B[32m[I 2023-02-19 23:30:57,292]\u001B[0m Trial 29 finished with value: 0.6458503769568079 and parameters: {'classifier': 'GradientBoostingClassifier', 'learning_rate': 0.027184410244864975, 'n_estimators ': 4}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:31:00,692]\u001B[0m Trial 30 finished with value: 0.7655628177173327 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 40, 'min_samples_split': 4}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   30.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:31:31,129]\u001B[0m Trial 31 finished with value: 0.7841902768080046 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 50, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   30.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:32:01,499]\u001B[0m Trial 32 finished with value: 0.7843412053257102 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 48, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:32:27,400]\u001B[0m Trial 33 finished with value: 0.7844412241896892 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 41, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:32:48,836]\u001B[0m Trial 34 finished with value: 0.784900697795234 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 35, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.5s finished\n",
      "\u001B[32m[I 2023-02-19 23:33:10,478]\u001B[0m Trial 35 finished with value: 0.7839851640942733 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 34, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   19.4s finished\n",
      "\u001B[32m[I 2023-02-19 23:33:30,007]\u001B[0m Trial 36 finished with value: 0.7833072751378527 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 32, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s finished\n",
      "\u001B[32m[I 2023-02-19 23:33:30,721]\u001B[0m Trial 37 finished with value: 0.6785466480864066 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 2, 'min_samples_split': 4}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s finished\n",
      "\u001B[32m[I 2023-02-19 23:33:34,216]\u001B[0m Trial 38 finished with value: 0.7773002354473837 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 5, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   22.6s finished\n",
      "\u001B[32m[I 2023-02-19 23:33:56,904]\u001B[0m Trial 39 finished with value: 0.7828054562554562 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 36, 'criterion': 'gini'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:34:00,294]\u001B[0m Trial 40 finished with value: 0.7606935696065497 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 15, 'min_samples_split': 2}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   28.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:34:29,258]\u001B[0m Trial 41 finished with value: 0.7840511447010989 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 45, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:34:54,672]\u001B[0m Trial 42 finished with value: 0.7849544815364266 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 39, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   23.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:35:18,648]\u001B[0m Trial 43 finished with value: 0.7843725656492436 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 39, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.5s finished\n",
      "\u001B[32m[I 2023-02-19 23:35:44,264]\u001B[0m Trial 44 finished with value: 0.7841139305344712 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 41, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.2s finished\n",
      "\u001B[32m[I 2023-02-19 23:36:01,604]\u001B[0m Trial 45 finished with value: 0.7837132878049933 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 28, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   25.7s finished\n",
      "\u001B[32m[I 2023-02-19 23:36:27,432]\u001B[0m Trial 46 finished with value: 0.7834765659637745 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 43, 'criterion': 'gini'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   22.3s finished\n",
      "\u001B[32m[I 2023-02-19 23:36:49,832]\u001B[0m Trial 47 finished with value: 0.7832212237003803 and parameters: {'classifier': 'RandomForestClassifier', 'n_estimators': 36, 'criterion': 'entropy'}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.6s finished\n",
      "\u001B[32m[I 2023-02-19 23:37:07,569]\u001B[0m Trial 48 finished with value: 0.6343997950398655 and parameters: {'classifier': 'GradientBoostingClassifier', 'learning_rate': 0.0015641481822164804, 'n_estimators ': 27}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.8s finished\n",
      "\u001B[32m[I 2023-02-19 23:37:10,459]\u001B[0m Trial 49 finished with value: 0.749572385317203 and parameters: {'classifier': 'DecisionTreeClassifier', 'max_depth': 13, 'min_samples_split': 5}. Best is trial 3 with value: 0.7856510911721721.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optimization with Optuna performed in 849.2120630741119 seconds ---\n",
      "Best params : {'classifier': 'RandomForestClassifier', 'n_estimators': 42, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if run_optuna:\n",
    "\n",
    "    # if classifier_name == 'DecisionTreeClassifier': n_trials = 100\n",
    "    # if classifier_name == 'RandomForestClassifier': n_trials = 10\n",
    "    # if classifier_name == 'GradientBoostingClassifier': n_trials = 3\n",
    "    n_trials = 50\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Define an objective function to be maximized.\n",
    "    def objective(trial):\n",
    "\n",
    "        # 2. Suggest values for the hyperparameters using a trial object.\n",
    "        classifier_name = trial.suggest_categorical('classifier', ['DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier'])\n",
    "        if classifier_name == 'DecisionTreeClassifier':\n",
    "            dt_max_depth         = trial.suggest_int('max_depth', 2, 50, log=True)\n",
    "            dt_min_samples_split = trial.suggest_int('min_samples_split', 2, 6)\n",
    "            classifier_obj = DecisionTreeClassifier(max_depth=dt_max_depth, min_samples_split=dt_min_samples_split)\n",
    "        else:\n",
    "            if classifier_name == 'RandomForestClassifier':\n",
    "                dt_n_estimators      = trial.suggest_int('n_estimators', 5, 50)\n",
    "                dt_criterion         = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "                classifier_obj = RandomForestClassifier(n_estimators=dt_n_estimators, criterion=dt_criterion)\n",
    "            else:\n",
    "                if classifier_name == 'GradientBoostingClassifier':\n",
    "                    dt_learning_rate = trial.suggest_float('learning_rate', 0.001, 1, log=True)\n",
    "                    dt_n_estimators  = trial.suggest_int('n_estimators ', 1, 30, log=True)\n",
    "                    classifier_obj = GradientBoostingClassifier(learning_rate=dt_learning_rate, n_estimators=dt_n_estimators)\n",
    "\n",
    "\n",
    "        score = cross_val_score(classifier_obj, X_train, y_train, cv=3, scoring=\"f1\", verbose=1)\n",
    "        accuracy = score.mean()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    # 3. Create a study object and optimize the objective function.\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(f\"--- Optimization with Optuna performed in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(f\"Best params : {study.best_params}\")\n",
    "\n",
    "    # fig = optuna.visualization.plot_param_importances(study)\n",
    "    # fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model RandomForestClassifier fit and trained in 13.853517532348633 seconds ---\n",
      "--- Params : {'n_estimators': 42, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Classe prédite      0     1\nClasse réelle              \n0               13212  2827\n1                1837  1879",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Classe prédite</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>Classe réelle</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13212</td>\n      <td>2827</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1837</td>\n      <td>1879</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85     16039\n",
      "           1       0.40      0.51      0.45      3716\n",
      "\n",
      "    accuracy                           0.76     19755\n",
      "   macro avg       0.64      0.66      0.65     19755\n",
      "weighted avg       0.79      0.76      0.77     19755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from my_libs.model_evaluator import ModelEvaluator\n",
    "\n",
    "params = study.best_params\n",
    "model_type = params['classifier']\n",
    "params.pop('classifier')\n",
    "\n",
    "evaluator = ModelEvaluator(model_type=model_type, params=params, X_train=X_train, y_train=y_train, X_test=X_test_final, y_test=y_test_final)\n",
    "model = evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] END ................learning_rate=0.001, n_estimators=2; total time=   0.5s\n",
      "[CV] END ................learning_rate=0.001, n_estimators=2; total time=   0.8s\n",
      "[CV] END ................learning_rate=0.001, n_estimators=2; total time=   0.5s\n",
      "[CV] END ...............learning_rate=0.001, n_estimators=15; total time=   2.7s\n",
      "[CV] END ...............learning_rate=0.001, n_estimators=15; total time=   3.8s\n",
      "[CV] END ...............learning_rate=0.001, n_estimators=15; total time=   4.0s\n",
      "[CV] END ...............learning_rate=0.001, n_estimators=30; total time=   6.8s\n",
      "[CV] END ...............learning_rate=0.001, n_estimators=30; total time=   5.6s\n",
      "[CV] END ...............learning_rate=0.001, n_estimators=30; total time=   6.7s\n",
      "[CV] END .................learning_rate=0.01, n_estimators=2; total time=   0.4s\n",
      "[CV] END .................learning_rate=0.01, n_estimators=2; total time=   0.4s\n",
      "[CV] END .................learning_rate=0.01, n_estimators=2; total time=   0.6s\n",
      "[CV] END ................learning_rate=0.01, n_estimators=15; total time=   3.3s\n",
      "[CV] END ................learning_rate=0.01, n_estimators=15; total time=   3.6s\n",
      "[CV] END ................learning_rate=0.01, n_estimators=15; total time=   2.7s\n",
      "[CV] END ................learning_rate=0.01, n_estimators=30; total time=   8.2s\n",
      "[CV] END ................learning_rate=0.01, n_estimators=30; total time=   6.2s\n",
      "[CV] END ................learning_rate=0.01, n_estimators=30; total time=   6.4s\n",
      "[CV] END ....................learning_rate=1, n_estimators=2; total time=   0.4s\n",
      "[CV] END ....................learning_rate=1, n_estimators=2; total time=   0.4s\n",
      "[CV] END ....................learning_rate=1, n_estimators=2; total time=   0.4s\n",
      "[CV] END ...................learning_rate=1, n_estimators=15; total time=   3.6s\n",
      "[CV] END ...................learning_rate=1, n_estimators=15; total time=   3.2s\n",
      "[CV] END ...................learning_rate=1, n_estimators=15; total time=   2.6s\n",
      "[CV] END ...................learning_rate=1, n_estimators=30; total time=   7.9s\n",
      "[CV] END ...................learning_rate=1, n_estimators=30; total time=   5.9s\n",
      "[CV] END ...................learning_rate=1, n_estimators=30; total time=   5.9s\n",
      "\n",
      "--- GradientBoostingClassifier - Optimization with GridSearchCV performed in 106.5535192489624 seconds ---\n",
      "Grid search params : {'learning_rate': [0.001, 0.01, 1], 'n_estimators': [2, 15, 30]}\n",
      "Best params : {'learning_rate': 1, 'n_estimators': 30}\n",
      "\n",
      "--- Model GradientBoostingClassifier fit and trained in 9.819509506225586 seconds ---\n",
      "--- Params : {'learning_rate': 1, 'n_estimators': 30}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Classe prédite      0     1\nClasse réelle              \n0               12917  3122\n1                1496  2220",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Classe prédite</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>Classe réelle</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12917</td>\n      <td>3122</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1496</td>\n      <td>2220</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85     16039\n",
      "           1       0.42      0.60      0.49      3716\n",
      "\n",
      "    accuracy                           0.77     19755\n",
      "   macro avg       0.66      0.70      0.67     19755\n",
      "weighted avg       0.81      0.77      0.78     19755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if run_gridSearchCV:\n",
    "\n",
    "    classifier_name = 'GradientBoostingClassifier'\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if classifier_name == 'DecisionTreeClassifier':\n",
    "        model = DecisionTreeClassifier()\n",
    "        params = {'max_depth' : [2, 10, 30, 50],\n",
    "                  'min_samples_split' : [2,4,6]\n",
    "                  }\n",
    "\n",
    "    if classifier_name == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier()\n",
    "        params = {'n_estimators' : [5,10,25,50],\n",
    "                  'criterion' : ('gini', 'entropy'),\n",
    "        }\n",
    "\n",
    "    if classifier_name == 'GradientBoostingClassifier':\n",
    "        model = GradientBoostingClassifier()\n",
    "        params = {'learning_rate' : [0.001, 0.01, 1],\n",
    "                  'n_estimators' : [2, 15, 30]\n",
    "                  }\n",
    "\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv = 3, verbose=2, scoring=\"f1\")\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"\\n--- {classifier_name} - Optimization with GridSearchCV performed in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(f\"Grid search params : {params}\")\n",
    "    print(f\"Best params : {grid.best_params_}\")\n",
    "\n",
    "    from my_libs.model_evaluator import ModelEvaluator\n",
    "    evaluator = ModelEvaluator(model_type=classifier_name, params=grid.best_params_, X_train=X_train, y_train=y_train, X_test=X_test_final, y_test=y_test_final)\n",
    "    model = evaluator.evaluate()\n",
    "    # feats = {}\n",
    "    # for feature, importance in zip(X_train.columns, grid.best_estimator_.feature_importances_):\n",
    "    #     feats[feature] = importance\n",
    "    #\n",
    "    # importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "    #\n",
    "    # # variables les plus importantes\n",
    "    # importances.sort_values(by='Gini-importance', ascending=False).head(20)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
