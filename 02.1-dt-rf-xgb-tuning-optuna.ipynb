{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_libs import lib_tools as pt\n",
    "\n",
    "run_type = 'dev'\n",
    "# run_type = 'prd'\n",
    "encoding_step = False\n",
    "\n",
    "if run_type == 'dev': filename_train, filename_test = 'df-dev-train.pkl', 'df-dev-test.pkl'\n",
    "if run_type == 'prd': filename_train, filename_test = 'df-prd-train.pkl', 'df-prd-test.pkl'\n",
    "\n",
    "# classifier_name = 'DecisionTreeClassifier'\n",
    "# classifier_name = 'RandomForestClassifier'\n",
    "# classifier_name = 'GradientBoostingClassifier'\n",
    "\n",
    "columns = ['catv', 'agg', 'dep', 'col', 'catr', 'catu', 'trajet', 'locp', 'circ', 'situ', 'lum', 'age_cls']\n",
    "X_train, y_train, X_test, y_test, X_test_final, y_test_final = pt.get_train_valid_test_data(filename_train, filename_test, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from my_libs.encoder_custom import EncoderCustom\n",
    "\n",
    "if encoding_step :\n",
    "    cols_target_encoded = ['dep']\n",
    "    cols_onehot_encoded = X_train.columns.drop(cols_target_encoded)\n",
    "\n",
    "    encoder = EncoderCustom(cols_target_encoded=cols_target_encoded, cols_onehot_encoded=cols_onehot_encoded)\n",
    "    X_train, y_train = encoder.transform(X_train, y_train, 'Train')\n",
    "    X_test,  y_test  = encoder.transform(X_test,  y_test,  'Test')\n",
    "    X_test_final, y_test_final = encoder.transform(X_test_final, y_test_final, 'Test')\n",
    "\n",
    "    X_train.to_pickle('./X_train.pkl')\n",
    "    y_train.to_pickle('./y_train.pkl')\n",
    "    X_test.to_pickle('./X_test.pkl')\n",
    "    y_test.to_pickle('./y_test.pkl')\n",
    "    X_test_final.to_pickle('./X_test_final.pkl')\n",
    "    y_test_final.to_pickle('./y_test_final.pkl')\n",
    "else:\n",
    "    X_train = pd.read_pickle(f'./X_train.pkl')\n",
    "    y_train = pd.read_pickle(f'./y_train.pkl')\n",
    "    X_test = pd.read_pickle(f'./X_test.pkl')\n",
    "    y_test = pd.read_pickle(f'./y_test.pkl')\n",
    "    X_test_final = pd.read_pickle(f'./X_test_final.pkl')\n",
    "    y_test_final = pd.read_pickle(f'./y_test_final.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Train dataset size : {X_train.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# if classifier_name == 'DecisionTreeClassifier': n_trials = 100\n",
    "# if classifier_name == 'RandomForestClassifier': n_trials = 10\n",
    "# if classifier_name == 'GradientBoostingClassifier': n_trials = 3\n",
    "n_trials = 10\n",
    "start_time = time.time()\n",
    "\n",
    "# 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "\n",
    "    # 2. Suggest values for the hyperparameters using a trial object.\n",
    "    # classifier_name = trial.suggest_categorical('classifier', ['DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier'])\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['RandomForestClassifier'])\n",
    "\n",
    "    if classifier_name == 'DecisionTreeClassifier':\n",
    "        dt_criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        dt_splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
    "        dt_max_depth = trial.suggest_int('max_depth', 2, 300, log=True)\n",
    "        dt_min_samples_split = trial.suggest_int('min_samples_split', 2, 6)\n",
    "        classifier_obj = DecisionTreeClassifier(criterion=dt_criterion, splitter=dt_splitter, max_depth=dt_max_depth, min_samples_split=dt_min_samples_split)\n",
    "    else:\n",
    "        if classifier_name == 'RandomForestClassifier':\n",
    "            dt_n_estimators = trial.suggest_int('n_estimators', 50, 150)\n",
    "            dt_criterion    = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "            dt_max_depth = trial.suggest_int('max_depth', 2, 20, log=True)\n",
    "            dt_min_samples_split = trial.suggest_int('min_samples_split', 2, 6)\n",
    "            classifier_obj = RandomForestClassifier(n_estimators=dt_n_estimators, criterion=dt_criterion)\n",
    "        else:\n",
    "            if classifier_name == 'GradientBoostingClassifier':\n",
    "                dt_learning_rate = trial.suggest_float('learning_rate', 0.001, 0.5, log=True)\n",
    "                dt_n_estimators  = trial.suggest_int('n_estimators', 50, 150)\n",
    "                classifier_obj = GradientBoostingClassifier(learning_rate=dt_learning_rate, n_estimators=dt_n_estimators)\n",
    "\n",
    "\n",
    "    score = cross_val_score(classifier_obj, X_train, y_train, cv=5, scoring=\"f1\", verbose=1)\n",
    "    accuracy = score.mean()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "print(f\"--- Optimization with Optuna performed in %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"Best params : {study.best_params}\")\n",
    "\n",
    "# fig = optuna.visualization.plot_param_importances(study)\n",
    "# fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from my_libs.model_evaluator import ModelEvaluator\n",
    "\n",
    "params = study.best_params\n",
    "model_type = params['classifier']\n",
    "params.pop('classifier')\n",
    "\n",
    "evaluator = ModelEvaluator(model_type=model_type, params=params, X_train=X_train, y_train=y_train, X_test=X_test_final, y_test=y_test_final)\n",
    "model = evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_contour(study, params=[list(params.keys())[0], list(params.keys())[1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(\n",
    "    study, target=lambda t: t.duration.total_seconds(), target_name=\"duration\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_edf(study)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
