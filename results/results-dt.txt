RESULTS WITH SMOTE APPLIED ONLY ON TRAIN DATA

sample size = 100000 -----------------------------------------------------------------------------------------------

[I 2023-02-21 10:33:22,963] Trial 49 finished with value: 0.7940376187958333 and
parameters: {'classifier': 'DecisionTreeClassifier', 'criterion': 'gini', 'splitter': 'best', 'max_depth': 229, 'min_samples_split': 6}.
Best is trial 35 with value: 0.7975938486572053.

--- Optimization with Optuna performed in 397.6700773239136 seconds ---
Best params : {'classifier': 'DecisionTreeClassifier', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 180, 'min_samples_split': 2}



sample size = 200000 -----------------------------------------------------------------------------------------------

[I 2023-02-21 08:29:21,599] Trial 49 finished with value: 0.7968767330470954
and parameters: {'classifier': 'DecisionTreeClassifier', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 51, 'min_samples_split': 6}.
Best is trial 31 with value: 0.8008841729603475.

--- Optimization with Optuna performed in 810.6341602802277 seconds ---
Best params : {'classifier': 'DecisionTreeClassifier', 'criterion': 'entropy', 'splitter': 'best', 'max_depth': 89, 'min_samples_split': 2}

Train dataset size : (195766, 70)

--- Model DecisionTreeClassifier fit and trained in 4.423078298568726 seconds ---
--- Params : {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 89, 'min_samples_split': 2}

    0       1
0   23198   9314
1   3588    3899

Classification report :
              precision    recall  f1-score   support

           0       0.87      0.71      0.78     32512
           1       0.30      0.52      0.38      7487

    accuracy                           0.68     39999
   macro avg       0.58      0.62      0.58     39999
weighted avg       0.76      0.68      0.71     39999


--------------------------------------------------------------------------------------------------------------------
RESULTS WITH SMOTE APPLIED ON TEST DATA

Decision tree - with SMOTE()
params = {
    'max_depth' : [10, 20, 30, 40 ,50],
    'criterion' : ('gini', 'entropy'),
    'max_features' : ('auto', 'sqrt', 'log2'),
    'min_samples_split' : (2,4,6)
}

Best score  :  0.7908690573906861
Best params :  {'criterion': 'entropy', 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_split': 2}
                   pre       rec       spe        f1       geo       iba       sup

          0       0.77      0.83      0.75      0.80      0.79      0.63     15490
          1       0.81      0.75      0.83      0.78      0.79      0.62     15490

avg / total       0.79      0.79      0.79      0.79      0.79      0.62     30980

--- performed in 107.06015729904175 seconds ---

--------------------------------------------------------------------------------------------------------------------
Decision tree - with UnderSampler()
params = {
    'max_depth' : [10, 20, 30, 40 ,50],
    'criterion' : ('gini', 'entropy'),
    'max_features' : ('auto', 'sqrt', 'log2'),
    'min_samples_split' : (2,4,6)
}

Best score  :  0.6920253000700978
Best params :  {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 4}
                   pre       rec       spe        f1       geo       iba       sup

          0       0.69      0.62      0.72      0.66      0.67      0.45      4469
          1       0.66      0.72      0.62      0.69      0.67      0.45      4469

avg / total       0.67      0.67      0.67      0.67      0.67      0.45      8938

--- performed in 35.237406969070435 seconds ---
--------------------------------------------------------------------------------------------------------------------
Decision tree - with OverSampler()
params = {
    'max_depth' : [10, 20, 30, 40 ,50],
    'criterion' : ('gini', 'entropy'),
    'max_features' : ('auto', 'sqrt', 'log2'),
    'min_samples_split' : (2,4,6)
}

Best score  :  0.7928331021768136
Best params :  {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 6}
                   pre       rec       spe        f1       geo       iba       sup

          0       0.77      0.84      0.75      0.80      0.79      0.63     15476
          1       0.83      0.75      0.84      0.78      0.79      0.62     15476

avg / total       0.80      0.79      0.79      0.79      0.79      0.63     30952

--- performed in 240.8479197025299 seconds ---
--------------------------------------------------------------------------------------------------------------------

Best score  :  0.7928331021768136
Best params :  {'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 6}
                   pre       rec       spe        f1       geo       iba       sup

          0       0.77      0.84      0.75      0.80      0.79      0.63     15476
          1       0.83      0.75      0.84      0.78      0.79      0.62     15476

avg / total       0.80      0.79      0.79      0.79      0.79      0.63     30952