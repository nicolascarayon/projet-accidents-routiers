{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBOOST CLASSIFIER ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train, Valid, Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_libs import lib_tools as pt\n",
    "\n",
    "# run_type = 'dev'\n",
    "run_type = 'prd'\n",
    "gen_sample = True\n",
    "find_best_params = False\n",
    "\n",
    "columns = ['catv', 'agg', 'dep', 'col', 'catr', 'catu', 'trajet', 'locp', 'circ', 'situ', 'lum', 'age_cls']\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = pt.get_train_valid_test_data(run_type, columns)\n",
    "print(\"Train, Valid and Test data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample data with SMOTEN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen_sample:\n",
    "    X_train_rs, y_train_rs = pt.get_data_resampled(X=X_train, y=y_train, verbose=1)\n",
    "    # Save data generated\n",
    "    X_train_rs.to_pickle(f'./pickles/X_train_smote_{run_type}_{X_train.shape[0]}.pkl')\n",
    "    y_train_rs.to_pickle(f'./pickles/y_train_smote_{run_type}_{X_train.shape[0]}.pkl')\n",
    "else:\n",
    "    # Load data previously generated\n",
    "    X_train_rs = pd.read_pickle(f'./pickles/X_train_smote_{run_type}_{X_train.shape[0]}.pkl')\n",
    "    y_train_rs = pd.read_pickle(f'./pickles/y_train_smote_{run_type}_{X_train.shape[0]}.pkl')\n",
    "\n",
    "pt.plot_data_augmentation(y_train, y_train_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best hyperparameters for model with Optuna (or load model previously fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "if find_best_params:\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        dt_iterations    = trial.suggest_int('iterations', 50, 2000, log=True)\n",
    "        dt_learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log=True)\n",
    "\n",
    "        classifier_obj = CatBoostClassifier(iterations=dt_iterations, learning_rate=dt_learning_rate, cat_features=list(X_train.columns), verbose=0)\n",
    "        score = cross_val_score(classifier_obj, X_train_rs, y_train_rs, cv=5, scoring=\"f1\", verbose=1)\n",
    "        accuracy = score.mean()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=5)\n",
    "\n",
    "    print(\"--- CatBoost Classifier - Optimization with Optuna performed in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(f\"Best params : {study.best_params}\")\n",
    "    \n",
    "    from optuna.visualization import plot_optimization_history\n",
    "    fig = plot_optimization_history(study)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_libs.model_evaluator import ModelEvaluator\n",
    "\n",
    "if find_best_params:\n",
    "    # model coming from optuna search\n",
    "    params = study.best_params\n",
    "    params['cat_features'] = list(X_train_rs.columns)\n",
    "else:\n",
    "    # train best model    \n",
    "    n_iter = 1400 if run_type == 'prd' else 200\n",
    "    l_r = 0.0811\n",
    "    params = {'iterations': n_iter, 'learning_rate': l_r, 'custom_loss': [\"Accuracy\",\"AUC\"],\n",
    "              'cat_features': list(X_train_rs.columns)}\n",
    "    \n",
    "model = CatBoostClassifier(**params, verbose=0)   \n",
    "model.fit(X_train_rs, y_train_rs, eval_set=(X_test, y_test), plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)    \n",
    "display(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
    "print(\"\\nClassification report -------------------------------\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tsv file learn_error.tsv\n",
    "data=pd.read_csv('catboost_info/learn_error.tsv',sep='\\t')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "axs = sns.lineplot(x=\"iter\", y=\"Logloss\", data=data)\n",
    "axs.set(ylim=(0,1))\n",
    "axs.set_title('Logloss during Catboost training');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curves (from estimator & from predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "RocCurveDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.plot(np.arange(0, 1, 0.01), np.arange(0, 1, 0.01))\n",
    "plt.title('Catboost - ROC Curve from estimator')\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, model.predict(X_test))\n",
    "plt.plot(np.arange(0, 1, 0.01), np.arange(0, 1, 0.01))\n",
    "plt.title('Catboost - ROC Curve from predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change proba threshold to improve f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, plot_roc_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "thresholds = np.arange(0.20, 0.80, 0.01)\n",
    "scores_f1 = []\n",
    "scores_prec = []\n",
    "scores_recall = []\n",
    "for k in thresholds:\n",
    "    y_pred = (model.predict_proba(X_test)[:,1] >= k).astype(bool)\n",
    "    scores_f1.append(f1_score(y_test, y_pred))\n",
    "    scores_prec.append(precision_score(y_test, y_pred))\n",
    "    scores_recall.append(recall_score(y_test, y_pred))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(2,1, figsize=(7,10))\n",
    "plt.grid()\n",
    "axs[0].plot(thresholds, scores_f1, label='f1')\n",
    "axs[0].set_title(\"Valeur du f1-score en fonction du seuil de probabilité d'attribution des classes\")\n",
    "axs[1].plot(thresholds, scores_f1, label='f1')\n",
    "axs[1].plot(thresholds, scores_recall, label='recall')\n",
    "axs[1].plot(thresholds, scores_prec, label='precision')\n",
    "axs[1].set_title(\"Valeur des métriques en fonction du seuil de probabilité d'attribution des classes\")\n",
    "axs[1].grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = (model.predict_proba(X_test)[:,1] >= 0.42).astype(bool)\n",
    "\n",
    "display(pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
    "\n",
    "print(\"\\nClassification report :\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash import SmartExplainer\n",
    "from my_libs import ref_labels\n",
    "import pickle\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "xpl = SmartExplainer(\n",
    "    model=model,\n",
    "    label_dict=ref_labels.dic_target,\n",
    "    preprocessing=ref_labels.dic_preproc,\n",
    "    features_dict=ref_labels.dic_features,  # Optional parameter\n",
    "    # preprocessing=encoder, # Optional: compile step can use inverse_transform method\n",
    "    # postprocessing=postprocess # Optional: see tutorial postprocessing\n",
    ")\n",
    "\n",
    "y_test.index = X_test.index\n",
    "\n",
    "xpl.compile(\n",
    "    x=X_test,\n",
    "    # y_pred=y_pred, # Optional: for your own prediction (by default: model.predict)\n",
    "    y_target=y_test, # Optional: allows to display True Values vs Predicted Values\n",
    ")\n",
    "\n",
    "app = xpl.run_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# Save the model to an h5 file using joblib\n",
    "dump(model, f'h5_models/model_cb_{run_type}_{X_train.shape[0]}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
