{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION  TREE CLASSIFIER ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train, Valid, Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_libs import lib_tools as pt\n",
    "\n",
    "# run_type = 'dev'\n",
    "run_type = 'prd'\n",
    "gen_sample = True\n",
    "find_best_params = False\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = pt.get_train_valid_test_data(run_type)\n",
    "print(\"Train, valid and Test data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample data with SMOTEN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen_sample:\n",
    "    X_train_rs, y_train_rs = pt.get_data_resampled(X=X_train, y=y_train, verbose=1)\n",
    "    # Save data generated\n",
    "    X_train_rs.to_pickle(f'./pickles/X_train_smote_{run_type}_dt_{X_train.shape[0]}.pkl')\n",
    "    y_train_rs.to_pickle(f'./pickles/y_train_smote_{run_type}_dt_{X_train.shape[0]}.pkl')\n",
    "else:\n",
    "    # Load data previously generated\n",
    "    X_train_rs = pd.read_pickle(f'./pickles/X_train_smote_{run_type}_dt_{X_train.shape[0]}.pkl')\n",
    "    y_train_rs = pd.read_pickle(f'./pickles/y_train_smote_{run_type}_dt_{X_train.shape[0]}.pkl')\n",
    "\n",
    "pt.plot_data_augmentation(y_train, y_train_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical data (target and one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_libs.encoder_custom import  EncoderCustom\n",
    "\n",
    "cols_target_encoded = ['dep']\n",
    "cols_onehot_encoded = X_train.columns.drop(cols_target_encoded)\n",
    "\n",
    "encoder = EncoderCustom(cols_target_encoded=cols_target_encoded, cols_onehot_encoded=cols_onehot_encoded)\n",
    "\n",
    "X_train_rs_enc, y_train_rs_enc = encoder.transform(X=X_train_rs, y=y_train_rs, datatype='Train')\n",
    "X_valid_enc, y_valid_enc = encoder.transform(X=X_valid, y=y_valid, datatype='Test')\n",
    "X_test_enc, y_test_enc = encoder.transform(X=X_test , y=y_test , datatype='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best hyperparameters for model with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if find_best_params:\n",
    "\n",
    "    n_trials = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        dt_criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        dt_splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
    "        dt_max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "        dt_min_samples_split = trial.suggest_int('min_samples_split', 2, 50)\n",
    "        classifier_obj = DecisionTreeClassifier(criterion=dt_criterion, splitter=dt_splitter, max_depth=dt_max_depth, min_samples_split=dt_min_samples_split)\n",
    "\n",
    "        score = cross_val_score(classifier_obj, X_train_rs_enc, y_train_rs_enc, cv=5, scoring=\"f1\", verbose=1)\n",
    "        accuracy = score.mean()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    # Create a study object and optimize the objective function.\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(f\"\\n--- Decision Tree Classifier - Optimization with Optuna performed in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(f\"Best params : {study.best_params}\")\n",
    "    \n",
    "    from optuna.visualization import plot_optimization_history\n",
    "    fig = plot_optimization_history(study)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if find_best_params:\n",
    "    # model coming from optuna search\n",
    "    params = study.best_params    \n",
    "else:\n",
    "    # train best model    \n",
    "    criterion = 'gini'\n",
    "    splitter = 'best'\n",
    "    max_depth = 16\n",
    "    min_samples_split = 11\n",
    "    params = {'criterion': criterion, 'splitter': splitter, 'max_depth': max_depth, 'min_samples_split': 5}\n",
    "    \n",
    "model = DecisionTreeClassifier(**params)   \n",
    "model.fit(X_train_rs_enc, y_train_rs_enc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot Train and Test learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Compute the learning curve\n",
    "train_sizes, train_scores, valid_scores = learning_curve(model, X_train_rs_enc, y_train_rs_enc, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Calculate the mean and standard deviation of the training and validation scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std  = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "valid_scores_std  = np.std(valid_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Decision Tree Classifier Learning Curve')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std, valid_scores_mean + valid_scores_std, alpha=0.1, color='g')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training Score')\n",
    "plt.plot(train_sizes, valid_scores_mean, 'o-', color='g', label='Validation Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test_enc)    \n",
    "display(pd.crosstab(y_test_enc, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
    "print(\"\\nClassification report -------------------------------\\n\")\n",
    "print(classification_report(y_test_enc, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curves (from estimator & from predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "RocCurveDisplay.from_estimator(model, X_test_enc, y_test_enc, ax=axs[0])\n",
    "axs[0].plot(np.arange(0, 1, 0.01), np.arange(0, 1, 0.01))\n",
    "axs[0].set_title('Gradient Boosting - ROC Curve from estimator')\n",
    "axs[0].grid(linestyle='--')\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test_enc, model.predict(X_test_enc), ax=axs[1])\n",
    "axs[1].plot(np.arange(0, 1, 0.01), np.arange(0, 1, 0.01))\n",
    "axs[1].set_title('Gradient Boosting - ROC Curve from predictions');\n",
    "axs[1].grid(linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# Save the model to an h5 file using joblib\n",
    "dump(model, f'h5_models/model_dt_{run_type}_{X_train.shape[0]}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
