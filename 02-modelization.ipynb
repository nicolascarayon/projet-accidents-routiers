{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quick = True             # work with sampled data to reduce computing time\n",
    "run_gridSearchCV = True # run or not hyperparameters optimization with GridSearchCV()\n",
    "run_optuna = True        # run or not hyperparameters optimization with Optuna\n",
    "\n",
    "filename = 'df-light.pkl' if quick else 'df-full.pkl'\n",
    "\n",
    "df = pd.read_pickle(f'./{filename}')\n",
    "data = df.iloc[:, 1:]\n",
    "target = df['grav']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display(data.info())\n",
    "# for col in data.columns:\n",
    "#     data[col] = data[col].astype('object')\n",
    "#\n",
    "# display(data.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "from my_libs.encoder_custom import EncoderCustom\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cols_target_encoded = []\n",
    "cols_onehot_encoded = X_train.columns.drop(cols_target_encoded)\n",
    "\n",
    "encoder = EncoderCustom(cols_target_encoded=cols_target_encoded, cols_onehot_encoded=cols_onehot_encoded)\n",
    "X_train_enc, y_train_enc = encoder.transform(X_train, y_train, 'Train')\n",
    "X_test_enc,  y_test_enc  = encoder.transform(X_test,  y_test,  'Test')\n",
    "\n",
    "print(\"--- Features encoding performed in %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if run_optuna:\n",
    "\n",
    "    start_time = time.time()\n",
    "    # classifier_name = 'DecisionTreeClassifier'\n",
    "    classifier_name = 'RandomForestClassifier'\n",
    "    # classifier_name = 'SVC'\n",
    "\n",
    "\n",
    "    # 1. Define an objective function to be maximized.\n",
    "    def objective(trial):\n",
    "\n",
    "        # 2. Suggest values for the hyperparameters using a trial object.\n",
    "        # classifier_name = trial.suggest_categorical('classifier', ['DecisionTreeClassifier', 'RandomForestClassifier', 'KNeighborsClassifier'])\n",
    "        if classifier_name == 'DecisionTreeClassifier':\n",
    "            dt_max_depth         = trial.suggest_int('max_depth', 2, 50, log=False)\n",
    "            dt_criterion         = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "            dt_max_features      = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "            dt_min_samples_split = trial.suggest_int('min_samples_split', 2, 6)\n",
    "            classifier_obj = DecisionTreeClassifier(max_depth=dt_max_depth, min_samples_split=dt_min_samples_split, criterion=dt_criterion, max_features=dt_max_features)\n",
    "        else:\n",
    "            if classifier_name == 'RandomForestClassifier':\n",
    "                dt_n_estimators      = trial.suggest_int('n_estimators', 20, 100)\n",
    "                dt_criterion         = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "                dt_max_depth         = trial.suggest_int('max_depth', 10, 50, log=False)\n",
    "                dt_min_samples_split = trial.suggest_int('min_samples_split', 2, 6)\n",
    "                classifier_obj = RandomForestClassifier(n_estimators=dt_n_estimators, criterion=dt_criterion, max_depth=dt_max_depth, min_samples_split=dt_min_samples_split)\n",
    "            else:\n",
    "                if classifier_name == 'SVC':\n",
    "                    dt_C = trial.suggest_float('C', 0.7, 1)\n",
    "                    dt_kernel = trial.suggest_categorical('kernel', ['rbf', 'linear'])\n",
    "                    classifier_obj = SVC(C=dt_C, kernel=dt_kernel)\n",
    "                else:\n",
    "                    if classifier_name == 'KNeighborsClassifier':\n",
    "                        dt_n_neighbors = trial.suggest_int('n_neighbors', 2, 4)\n",
    "                        dt_weights     = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "                        classifier_obj = KNeighborsClassifier(n_neighbors=dt_n_neighbors, weights=dt_weights)\n",
    "\n",
    "        score = cross_val_score(classifier_obj, X_train_enc, y_train_enc, cv=3, scoring=\"f1\", verbose=1)\n",
    "        accuracy = score.mean()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    # 3. Create a study object and optimize the objective function.\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=200)\n",
    "\n",
    "    print(\"--- Optimization with Optuna performed in %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best model\n",
    "# params = {'classifier': 'RandomForestClassifier', 'n_estimators': 26, 'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 3}\n",
    "# params = {'classifier': 'RandomForestClassifier', 'n_estimators': 26, 'criterion': 'entropy', 'max_depth': 47, 'min_samples_split': 2}\n",
    "# params = {'classifier': 'DecisionTreeClassifier', 'max_depth': 32, 'criterion': 'entropy', 'max_features': 'log2', 'min_samples_split': 5}\n",
    "\n",
    "\n",
    "params_dt = {'max_depth': 15, 'criterion': 'entropy', 'max_features': 'auto', 'min_samples_split': 3}\n",
    "params_rf = {'n_estimators': 34, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "if run_gridSearchCV:\n",
    "    start_time = time.time()\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    params = {\n",
    "        'n_estimators' : [10, 20, 30, 40 ,50],\n",
    "        'criterion' : ('gini', 'entropy'),\n",
    "        'max_depth' : [10, 20],\n",
    "        'min_samples_split' : (2,4)\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv = 3, verbose=10, scoring=\"f1\")\n",
    "    grid.fit(X_train_enc, y_train_enc)\n",
    "\n",
    "    print('Best score  : ', grid.best_score_)\n",
    "    print('Best params : ', grid.best_params_)\n",
    "\n",
    "    y_pred = grid.predict(X_test_enc)\n",
    "    print(classification_report_imbalanced(y_test_enc, y_pred))\n",
    "\n",
    "    print(f\"model  : {model}\")\n",
    "    print(f\"params : {params}\")\n",
    "    print(\"--- Optimization with GridSearchCV performed in %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    feats = {}\n",
    "    for feature, importance in zip(X_train_enc.columns, grid.best_estimator_.feature_importances_):\n",
    "        feats[feature] = importance\n",
    "\n",
    "    importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "\n",
    "    # 8 variables les plus importantes\n",
    "    importances.sort_values(by='Gini-importance', ascending=False).head(20)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
