{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# RANDOM FOREST CLASSIFIER ---------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Train, Valid, Test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_libs import lib_tools as pt\n",
    "\n",
    "# run_type = 'dev'\n",
    "run_type = 'prd'\n",
    "gen_sample = True\n",
    "find_best_params = True\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = pt.get_train_valid_test_data(run_type)\n",
    "print(\"Train, valid and Test data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resample data with SMOTEN()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if gen_sample:\n",
    "    X_train_rs, y_train_rs = pt.get_data_resampled(X=X_train, y=y_train, verbose=1)\n",
    "    # Save data generated\n",
    "    X_train_rs.to_pickle(f'./pickles/X_train_smote_{run_type}.pkl')\n",
    "    y_train_rs.to_pickle(f'./pickles/y_train_smote_{run_type}.pkl')\n",
    "else:\n",
    "    # Load data previously generated\n",
    "    X_train_rs = pd.read_pickle(f'./pickles/X_train_smote_{run_type}.pkl')\n",
    "    y_train_rs = pd.read_pickle(f'./pickles/y_train_smote_{run_type}.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encode categorical data (target and one hot encoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from my_libs.encoder_custom import  EncoderCustom\n",
    "\n",
    "cols_target_encoded = ['dep']\n",
    "cols_onehot_encoded = X_train.columns.drop(cols_target_encoded)\n",
    "\n",
    "encoder = EncoderCustom(cols_target_encoded=cols_target_encoded, cols_onehot_encoded=cols_onehot_encoded)\n",
    "\n",
    "X_train_rs_enc, y_train_rs_enc = encoder.transform(X=X_train_rs, y=y_train_rs, datatype='Train')\n",
    "X_valid_enc, y_valid_enc = encoder.transform(X=X_valid, y=y_valid, datatype='Test')\n",
    "X_test_enc , y_test_enc  = encoder.transform(X=X_test , y=y_test , datatype='Test')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find best hyperparameters for model with Optuna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if find_best_params:\n",
    "\n",
    "    n_trials = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        dt_n_estimators = trial.suggest_int('n_estimators', 50, 150)\n",
    "        dt_criterion    = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        dt_max_depth = trial.suggest_int('max_depth', 2, 20, log=True)\n",
    "        dt_min_samples_split = trial.suggest_int('min_samples_split', 2, 6)\n",
    "        classifier_obj = RandomForestClassifier(n_estimators=dt_n_estimators, criterion=dt_criterion, max_depth=dt_max_depth, min_samples_split=dt_min_samples_split)\n",
    "\n",
    "        score = cross_val_score(classifier_obj, X_train_rs_enc, y_train_rs_enc, cv=5, scoring=\"f1\", verbose=1)\n",
    "        accuracy = score.mean()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    # Create a study object and optimize the objective function.\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(f\"\\n--- Random Forest Classifier - Optimization with Optuna performed in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(f\"Best params : {study.best_params}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if find_best_params:\n",
    "    from optuna.visualization import plot_optimization_history\n",
    "    fig = plot_optimization_history(study)\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from my_libs.model_evaluator import ModelEvaluator\n",
    "\n",
    "if find_best_params:\n",
    "\n",
    "    params = study.best_params\n",
    "\n",
    "    evaluator = ModelEvaluator(model_type='RandomForestClassifier', params=params, X_train=X_train_rs_enc, y_train=y_train_rs_enc, X_test=X_test_enc, y_test=y_test_enc)\n",
    "    model = evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit best model - Plot Train and Test learning curves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Train the best model\n",
    "params = study.best_params\n",
    "model = RandomForestClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Compute the learning curve\n",
    "train_sizes, train_scores, valid_scores = learning_curve(model, X_train_rs_enc, y_train_rs_enc, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Calculate the mean and standard deviation of the training and validation scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std  = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "valid_scores_std  = np.std(valid_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Random Forest Classifier Learning Curve')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std, valid_scores_mean + valid_scores_std, alpha=0.1, color='g')\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training Score')\n",
    "plt.plot(train_sizes, valid_scores_mean, 'o-', color='g', label='Validation Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model to h5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# Save the model to an h5 file using joblib\n",
    "dump(model, f'h5_models/model_rf_{run_type}.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
