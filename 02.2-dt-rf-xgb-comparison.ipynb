{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quick = True\n",
    "\n",
    "if quick:\n",
    "    start_year, end_year, chk, sampled, filename = [2005, 2021, False, True, 'df-light.pkl']\n",
    "else:\n",
    "    start_year, end_year, chk, sampled, filename = [2005, 2021, True, False, 'df-full.pkl']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_pickle(f'./{filename}')\n",
    "data = df.iloc[:, 1:]\n",
    "target = df['grav']\n",
    "\n",
    "data = data.drop(columns=['an'],axis=1)\n",
    "data = data[['catv', 'agg', 'dep', 'col', 'catr', 'catu', 'trajet', 'locp', 'circ', 'situ', 'lum', 'age_cls']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=222)\n",
    "# X_train, y_train, X_test, y_test = pt.train_test_split_along_time(data, target, 2018)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "from my_libs.encoder_custom import EncoderCustom\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# cols_target_encoded = ['dep', 'age']\n",
    "cols_target_encoded = []\n",
    "cols_onehot_encoded = X_train.columns.drop(cols_target_encoded)\n",
    "\n",
    "encoder = EncoderCustom(cols_target_encoded=cols_target_encoded, cols_onehot_encoded=cols_onehot_encoded)\n",
    "\n",
    "X_train_enc, y_train_enc = encoder.transform(X_train, y_train, 'Train')\n",
    "X_test_enc,  y_test_enc  = encoder.transform(X_test,  y_test,  'Test')\n",
    "\n",
    "print(\"--- Features encoding performed in %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from my_libs.model_evaluator import ModelEvaluator\n",
    "\n",
    "# params_dt = {'max_depth': 15, 'criterion': 'entropy', 'max_features': 'auto', 'min_samples_split': 3}\n",
    "params_dt = {'max_depth': 11, 'criterion': 'gini', 'max_features': 'auto', 'min_samples_split': 4}\n",
    "\n",
    "model_type = 'DecisionTreeClassifier'\n",
    "\n",
    "evaluator = ModelEvaluator(model_type=model_type, params=params_dt, X_train=X_train_enc, y_train=y_train_enc, X_test=X_test_enc, y_test=y_test_enc)\n",
    "model = evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from my_libs.model_evaluator import ModelEvaluator\n",
    "\n",
    "# params_rf_old = {'n_estimators': 34, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}\n",
    "# params_rf = {'n_estimators': 57, 'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 4}\n",
    "params_rf = {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "model_type = 'RandomForestClassifier'\n",
    "\n",
    "evaluator = ModelEvaluator(model_type=model_type, params=params_rf, X_train=X_train_enc, y_train=y_train_enc, X_test=X_test_enc, y_test=y_test_enc)\n",
    "model = evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from my_libs.model_evaluator import ModelEvaluator\n",
    "\n",
    "best_params = {'learning_rate': 0.22, 'n_estimators': 51}\n",
    "model_type = 'GradientBoostingClassifier'\n",
    "\n",
    "evaluator = ModelEvaluator(model_type=model_type, params=best_params, X_train=X_train_enc, y_train=y_train_enc, X_test=X_test_enc, y_test=y_test_enc)\n",
    "model = evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shapash import SmartExplainer\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "xpl = SmartExplainer(\n",
    "    model=model,\n",
    "    # features_dict=house_dict,  # Optional parameter\n",
    "    # preprocessing=encoder, # Optional: compile step can use inverse_transform method\n",
    "    # postprocessing=postprocess # Optional: see tutorial postprocessing\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "compile_df = X_test\n",
    "compile_df['y_pred'] = y_pred\n",
    "\n",
    "xpl.compile(\n",
    "    x=compile_df.drop(columns=['y_pred'], axis=1),\n",
    "    y_pred=compile_df['y_pred'], # Optional: for your own prediction (by default: model.predict)\n",
    "    y_target=pd.Series(y_test), # Optional: allows to display True Values vs Predicted Values\n",
    ")\n",
    "\n",
    "app = xpl.run_app()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
